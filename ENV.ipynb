{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1f786-231e-4759-9422-b22058e820a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ======================================================================\n",
    "# 1. Download COCO Dataset Directly from Official Website\n",
    "# ======================================================================\n",
    "def download_and_extract(url, save_dir, zip_name):\n",
    "    \"\"\"Download and extract a ZIP file from a URL.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    zip_path = os.path.join(save_dir, zip_name)\n",
    "    \n",
    "    # Download with progress bar\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1KB\n",
    "    progress_bar = tqdm(total=total_size, unit='B', unit_scale=True, desc=f\"Downloading {zip_name}\")\n",
    "    \n",
    "    with open(zip_path, 'wb') as f:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            f.write(data)\n",
    "    progress_bar.close()\n",
    "    \n",
    "    # Extract\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(save_dir)\n",
    "    os.remove(zip_path)  # Delete ZIP after extraction\n",
    "\n",
    "# COCO Dataset URLs (2017 version)\n",
    "coco_urls = {\n",
    "    \"train_images\": \"http://images.cocodataset.org/zips/train2017.zip\",\n",
    "    \"val_images\": \"http://images.cocodataset.org/zips/val2017.zip\",\n",
    "    \"annotations\": \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "}\n",
    "\n",
    "# Download and extract all files\n",
    "data_dir = \"data/coco\"\n",
    "for key, url in coco_urls.items():\n",
    "    if \"images\" in key:\n",
    "        save_path = os.path.join(data_dir, \"images\")\n",
    "    else:\n",
    "        save_path = os.path.join(data_dir, \"annotations\")\n",
    "    download_and_extract(url, save_path, f\"{key}.zip\")\n",
    "\n",
    "# ======================================================================\n",
    "# 2. Prepare Dataset for Training\n",
    "# ======================================================================\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((640, 640)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load COCO dataset\n",
    "dataset = datasets.CocoDetection(\n",
    "    root=os.path.join(data_dir, \"images/train2017\"),\n",
    "    annFile=os.path.join(data_dir, \"annotations/instances_train2017.json\"),\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split dataset (80% train, 10% val, 10% test)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# ======================================================================\n",
    "# 3. Analyze Class Distribution (Visualization)\n",
    "# ======================================================================\n",
    "cat_ids = dataset.coco.getCatIds()\n",
    "categories = [dataset.coco.loadCats(cat_id)[0]['name'] for cat_id in cat_ids]\n",
    "category_counts = [len(dataset.coco.getAnnIds(catIds=cat_id)) for cat_id in cat_ids]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(categories, category_counts)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"COCO Class Distribution\")\n",
    "plt.savefig(\"class_distribution.png\")\n",
    "plt.show()\n",
    "\n",
    "# ======================================================================\n",
    "# 4. Train YOLOv5 Model\n",
    "# ======================================================================\n",
    "model = YOLO('yolov5s.pt')  # Load pretrained model\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='coco.yaml',  # Config file (auto-detects paths)\n",
    "    epochs=50,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    plots=True,  # Save training plots\n",
    "    val=True     # Validate on val_set\n",
    ")\n",
    "\n",
    "# ======================================================================\n",
    "# 5. Evaluate Model\n",
    "# ======================================================================\n",
    "metrics = model.val()  # Evaluate on test_set\n",
    "print(f\"mAP@0.5: {metrics.box.map:.2f}, Precision: {metrics.box.p:.2f}, Recall: {metrics.box.r:.2f}\")\n",
    "\n",
    "# Plot training curves\n",
    "results_df = pd.DataFrame(results.results_dict)\n",
    "plt.figure()\n",
    "plt.plot(results_df['train/loss'], label='Training Loss')\n",
    "plt.plot(results_df['val/loss'], label='Validation Loss')\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"loss_curves.png\")\n",
    "plt.show()\n",
    "\n",
    "# ======================================================================\n",
    "# 6. Run Inference on a Satellite Image\n",
    "# ======================================================================\n",
    "\n",
    "results = model.predict('satellite_image.jpg', conf=0.5)\n",
    "results[0].save('detection_output.jpg')  \n",
    "\n",
    "# Print detected objects\n",
    "print(results[0].pandas().xyxy[0][['name', 'confidence', 'xmin', 'ymin', 'xmax', 'ymax']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586aa238-9d96-481a-a851-4b6878877058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
